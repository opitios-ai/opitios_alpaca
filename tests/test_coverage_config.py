"""
æµ‹è¯•è¦†ç›–ç‡é…ç½®å’Œè´¨é‡æŒ‡æ ‡
é…ç½®ä»£ç è¦†ç›–ç‡åˆ†æã€è´¨é‡é—¨ç¦å’Œå›å½’æµ‹è¯•å¥—ä»¶
"""

import pytest
import coverage
import os
import sys
import json
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


class CoverageAnalyzer:
    """ä»£ç è¦†ç›–ç‡åˆ†æå™¨"""
    
    def __init__(self, source_dirs=None, exclude_patterns=None):
        self.source_dirs = source_dirs or ['app']
        self.exclude_patterns = exclude_patterns or [
            '*/tests/*',
            '*/test_*',
            '*/conftest.py',
            '*/migrations/*',
            '*/venv/*',
            '*/__pycache__/*',
            '*/static/*',
            '*/templates/*'
        ]
        self.coverage_obj = None
        
    def start_coverage(self):
        """å¼€å§‹ä»£ç è¦†ç›–ç‡æ”¶é›†"""
        self.coverage_obj = coverage.Coverage(
            source=self.source_dirs,
            omit=self.exclude_patterns,
            branch=True,  # å¯ç”¨åˆ†æ”¯è¦†ç›–
            config_file=False
        )
        self.coverage_obj.start()
        
    def stop_coverage(self):
        """åœæ­¢ä»£ç è¦†ç›–ç‡æ”¶é›†"""
        if self.coverage_obj:
            self.coverage_obj.stop()
            
    def save_coverage_data(self, data_file='.coverage'):
        """ä¿å­˜è¦†ç›–ç‡æ•°æ®"""
        if self.coverage_obj:
            self.coverage_obj.save()
            
    def generate_coverage_report(self, output_dir='coverage_reports'):
        """ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š"""
        if not self.coverage_obj:
            return None
            
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_dir = output_path / 'html'
        self.coverage_obj.html_report(directory=str(html_dir))
        
        # ç”ŸæˆXMLæŠ¥å‘Š
        xml_file = output_path / 'coverage.xml'
        self.coverage_obj.xml_report(outfile=str(xml_file))
        
        # ç”ŸæˆJSONæŠ¥å‘Š
        json_file = output_path / 'coverage.json'
        with open(json_file, 'w') as f:
            json.dump(self.get_coverage_data(), f, indent=2)
        
        return {
            'html_report': html_dir,
            'xml_report': xml_file,
            'json_report': json_file
        }
    
    def get_coverage_data(self):
        """è·å–è¦†ç›–ç‡æ•°æ®"""
        if not self.coverage_obj:
            return None
            
        # è·å–æ€»ä½“ç»Ÿè®¡
        total = self.coverage_obj.report(show_missing=False, file=None)
        
        # è·å–æ–‡ä»¶çº§åˆ«ç»Ÿè®¡
        file_data = {}
        analysis_data = self.coverage_obj.get_data()
        
        for filename in analysis_data.measured_files():
            try:
                analysis = self.coverage_obj._analyze(filename)
                file_data[filename] = {
                    'statements': len(analysis.statements),
                    'missing': len(analysis.missing),
                    'excluded': len(analysis.excluded),
                    'coverage_percent': (len(analysis.statements) - len(analysis.missing)) / len(analysis.statements) * 100 if analysis.statements else 0
                }
            except Exception as e:
                file_data[filename] = {'error': str(e)}
        
        return {
            'total_coverage': total,
            'timestamp': datetime.now().isoformat(),
            'files': file_data
        }


class QualityGate:
    """è´¨é‡é—¨ç¦"""
    
    def __init__(self):
        self.thresholds = {
            'line_coverage_min': 80.0,      # æœ€ä½è¡Œè¦†ç›–ç‡
            'branch_coverage_min': 70.0,    # æœ€ä½åˆ†æ”¯è¦†ç›–ç‡
            'complexity_max': 10,           # æœ€å¤§åœˆå¤æ‚åº¦
            'duplicates_max': 3.0,          # æœ€å¤§é‡å¤ç‡ï¼ˆ%ï¼‰
            'maintainability_min': 70.0,    # æœ€ä½å¯ç»´æŠ¤æ€§æŒ‡æ•°
        }
        
    def check_coverage_threshold(self, coverage_data):
        """æ£€æŸ¥è¦†ç›–ç‡é˜ˆå€¼"""
        results = {
            'passed': True,
            'checks': []
        }
        
        total_coverage = coverage_data.get('total_coverage', 0)
        
        # æ£€æŸ¥è¡Œè¦†ç›–ç‡
        line_check = {
            'name': 'Line Coverage',
            'actual': total_coverage,
            'threshold': self.thresholds['line_coverage_min'],
            'passed': total_coverage >= self.thresholds['line_coverage_min']
        }
        results['checks'].append(line_check)
        
        if not line_check['passed']:
            results['passed'] = False
            
        return results
    
    def check_file_coverage(self, coverage_data, critical_files=None):
        """æ£€æŸ¥å…³é”®æ–‡ä»¶è¦†ç›–ç‡"""
        critical_files = critical_files or [
            'app/account_pool.py',
            'app/middleware.py',
            'app/routes.py',
            'app/alpaca_client.py'
        ]
        
        results = {
            'passed': True,
            'files': []
        }
        
        files_data = coverage_data.get('files', {})
        
        for critical_file in critical_files:
            matching_files = [f for f in files_data.keys() if critical_file in f]
            
            for file_path in matching_files:
                file_data = files_data[file_path]
                coverage_percent = file_data.get('coverage_percent', 0)
                
                file_check = {
                    'file': file_path,
                    'coverage': coverage_percent,
                    'threshold': self.thresholds['line_coverage_min'],
                    'passed': coverage_percent >= self.thresholds['line_coverage_min']
                }
                
                results['files'].append(file_check)
                
                if not file_check['passed']:
                    results['passed'] = False
        
        return results
    
    def generate_quality_report(self, coverage_data, output_file='quality_report.json'):
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'coverage_check': self.check_coverage_threshold(coverage_data),
            'file_coverage_check': self.check_file_coverage(coverage_data),
            'thresholds': self.thresholds,
            'overall_passed': True
        }
        
        # æ£€æŸ¥æ•´ä½“æ˜¯å¦é€šè¿‡
        if not report['coverage_check']['passed'] or not report['file_coverage_check']['passed']:
            report['overall_passed'] = False
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        return report


class RegressionTestSuite:
    """å›å½’æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self, baseline_file='test_baseline.json'):
        self.baseline_file = baseline_file
        self.baseline_data = self.load_baseline()
        
    def load_baseline(self):
        """åŠ è½½åŸºçº¿æ•°æ®"""
        if os.path.exists(self.baseline_file):
            with open(self.baseline_file, 'r') as f:
                return json.load(f)
        return {}
    
    def save_baseline(self, data):
        """ä¿å­˜åŸºçº¿æ•°æ®"""
        with open(self.baseline_file, 'w') as f:
            json.dump(data, f, indent=2)
    
    def run_regression_tests(self):
        """è¿è¡Œå›å½’æµ‹è¯•"""
        # å®šä¹‰æ ¸å¿ƒæµ‹è¯•å¥—ä»¶
        core_tests = [
            'tests/test_account_pool.py::TestAccountConnectionPool::test_get_connection_success',
            'tests/test_middleware_auth.py::TestJWTTokenOperations::test_create_jwt_token_basic',
            'tests/test_routing_load_balancing.py::TestRoutingStrategies::test_round_robin_basic',
            'tests/test_error_handling_recovery.py::TestConnectionPoolErrorHandling::test_connection_creation_failure',
        ]
        
        results = {}
        
        for test in core_tests:
            try:
                cmd = ['python', '-m', 'pytest', test, '-v', '--tb=short']
                result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
                
                results[test] = {
                    'passed': result.returncode == 0,
                    'output': result.stdout,
                    'error': result.stderr if result.stderr else None
                }
                
            except Exception as e:
                results[test] = {
                    'passed': False,
                    'error': str(e)
                }
        
        return results
    
    def compare_with_baseline(self, current_results):
        """ä¸åŸºçº¿å¯¹æ¯”"""
        comparison = {
            'timestamp': datetime.now().isoformat(),
            'regression_detected': False,
            'new_failures': [],
            'recovered_tests': [],
            'unchanged': []
        }
        
        for test, current_result in current_results.items():
            baseline_result = self.baseline_data.get(test, {})
            baseline_passed = baseline_result.get('passed', None)
            current_passed = current_result.get('passed', False)
            
            if baseline_passed is None:
                # æ–°æµ‹è¯•
                comparison['unchanged'].append({
                    'test': test,
                    'status': 'new_test',
                    'current': current_passed
                })
            elif baseline_passed and not current_passed:
                # å›å½’ï¼šä¹‹å‰é€šè¿‡ï¼Œç°åœ¨å¤±è´¥
                comparison['new_failures'].append({
                    'test': test,
                    'previous': baseline_passed,
                    'current': current_passed,
                    'error': current_result.get('error')
                })
                comparison['regression_detected'] = True
            elif not baseline_passed and current_passed:
                # æ¢å¤ï¼šä¹‹å‰å¤±è´¥ï¼Œç°åœ¨é€šè¿‡
                comparison['recovered_tests'].append({
                    'test': test,
                    'previous': baseline_passed,
                    'current': current_passed
                })
            else:
                # çŠ¶æ€æœªå˜
                comparison['unchanged'].append({
                    'test': test,
                    'status': 'unchanged',
                    'passed': current_passed
                })
        
        return comparison


class TestQualityManager:
    """æµ‹è¯•è´¨é‡ç®¡ç†å™¨"""
    
    def __init__(self, output_dir='quality_reports'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
    def run_full_quality_analysis(self):
        """è¿è¡Œå®Œæ•´è´¨é‡åˆ†æ"""
        print("Starting comprehensive quality analysis...")
        
        # 1. è¿è¡Œæµ‹è¯•å¹¶æ”¶é›†è¦†ç›–ç‡
        coverage_analyzer = CoverageAnalyzer()
        coverage_analyzer.start_coverage()
        
        try:
            # è¿è¡Œæµ‹è¯•å¥—ä»¶
            print("Running test suite with coverage...")
            cmd = [
                'python', '-m', 'pytest',
                'tests/',
                '-v',
                '--tb=short',
                '-x',  # é‡åˆ°ç¬¬ä¸€ä¸ªå¤±è´¥å°±åœæ­¢
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            test_success = result.returncode == 0
            
        finally:
            coverage_analyzer.stop_coverage()
        
        # 2. ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
        print("Generating coverage reports...")
        coverage_reports = coverage_analyzer.generate_coverage_report(
            self.output_dir / f'coverage_{self.timestamp}'
        )
        coverage_data = coverage_analyzer.get_coverage_data()
        
        # 3. è´¨é‡é—¨ç¦æ£€æŸ¥
        print("Running quality gate checks...")
        quality_gate = QualityGate()
        quality_report = quality_gate.generate_quality_report(
            coverage_data,
            self.output_dir / f'quality_report_{self.timestamp}.json'
        )
        
        # 4. å›å½’æµ‹è¯•
        print("Running regression tests...")
        regression_suite = RegressionTestSuite(
            self.output_dir / 'test_baseline.json'
        )
        regression_results = regression_suite.run_regression_tests()
        regression_comparison = regression_suite.compare_with_baseline(regression_results)
        
        # 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        comprehensive_report = {
            'timestamp': self.timestamp,
            'test_execution': {
                'success': test_success,
                'output': result.stdout if 'result' in locals() else None,
                'error': result.stderr if 'result' in locals() else None
            },
            'coverage': coverage_data,
            'quality_gate': quality_report,
            'regression': regression_comparison,
            'reports': {
                'coverage_html': str(coverage_reports['html_report']) if coverage_reports else None,
                'coverage_xml': str(coverage_reports['xml_report']) if coverage_reports else None,
                'quality_json': str(self.output_dir / f'quality_report_{self.timestamp}.json')
            }
        }
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        comprehensive_file = self.output_dir / f'comprehensive_report_{self.timestamp}.json'
        with open(comprehensive_file, 'w') as f:
            json.dump(comprehensive_report, f, indent=2)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        self.generate_html_quality_report(comprehensive_report)
        
        # æ›´æ–°åŸºçº¿ï¼ˆå¦‚æœæ²¡æœ‰å›å½’ï¼‰
        if not regression_comparison['regression_detected']:
            regression_suite.save_baseline(regression_results)
        
        # æ‰“å°æ‘˜è¦
        self.print_quality_summary(comprehensive_report)
        
        return comprehensive_report
    
    def generate_html_quality_report(self, report):
        """ç”ŸæˆHTMLè´¨é‡æŠ¥å‘Š"""
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Quality Report - {report['timestamp']}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background-color: #f8f9fa; padding: 20px; border-radius: 5px; }}
        .section {{ margin: 20px 0; padding: 15px; border-radius: 5px; }}
        .success {{ background-color: #d4edda; border-left: 5px solid #28a745; }}
        .warning {{ background-color: #fff3cd; border-left: 5px solid #ffc107; }}
        .danger {{ background-color: #f8d7da; border-left: 5px solid #dc3545; }}
        .metric {{ display: inline-block; margin: 10px; padding: 15px; background-color: #f8f9fa; border-radius: 5px; }}
        .metric-value {{ font-size: 24px; font-weight: bold; }}
        .metric-label {{ font-size: 14px; color: #6c757d; }}
        pre {{ background-color: #f8f9fa; padding: 10px; border-radius: 3px; overflow-x: auto; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>Code Quality Report</h1>
        <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p>Report ID: {report['timestamp']}</p>
    </div>
"""
        
        # æµ‹è¯•æ‰§è¡Œç»“æœ
        test_class = "success" if report['test_execution']['success'] else "danger"
        html_content += f"""
    <div class="section {test_class}">
        <h2>Test Execution</h2>
        <p><strong>Status:</strong> {'âœ“ PASSED' if report['test_execution']['success'] else 'âœ— FAILED'}</p>
    </div>
"""
        
        # è¦†ç›–ç‡ä¿¡æ¯
        coverage = report.get('coverage', {})
        coverage_percent = coverage.get('total_coverage', 0)
        coverage_class = "success" if coverage_percent >= 80 else "warning" if coverage_percent >= 60 else "danger"
        
        html_content += f"""
    <div class="section {coverage_class}">
        <h2>Code Coverage</h2>
        <div class="metric">
            <div class="metric-value">{coverage_percent:.1f}%</div>
            <div class="metric-label">Total Coverage</div>
        </div>
    </div>
"""
        
        # è´¨é‡é—¨ç¦
        quality_gate = report.get('quality_gate', {})
        gate_class = "success" if quality_gate.get('overall_passed', False) else "danger"
        
        html_content += f"""
    <div class="section {gate_class}">
        <h2>Quality Gate</h2>
        <p><strong>Status:</strong> {'âœ“ PASSED' if quality_gate.get('overall_passed', False) else 'âœ— FAILED'}</p>
    </div>
"""
        
        # å›å½’æµ‹è¯•
        regression = report.get('regression', {})
        regression_class = "success" if not regression.get('regression_detected', False) else "danger"
        
        html_content += f"""
    <div class="section {regression_class}">
        <h2>Regression Analysis</h2>
        <p><strong>Status:</strong> {'âœ“ NO REGRESSION' if not regression.get('regression_detected', False) else 'âœ— REGRESSION DETECTED'}</p>
        <p>New Failures: {len(regression.get('new_failures', []))}</p>
        <p>Recovered Tests: {len(regression.get('recovered_tests', []))}</p>
    </div>
"""
        
        html_content += """
</body>
</html>
"""
        
        html_file = self.output_dir / f'quality_report_{self.timestamp}.html'
        with open(html_file, 'w') as f:
            f.write(html_content)
        
        print(f"HTML quality report: {html_file}")
    
    def print_quality_summary(self, report):
        """æ‰“å°è´¨é‡æ‘˜è¦"""
        print(f"\n{'='*60}")
        print("QUALITY ANALYSIS SUMMARY")
        print(f"{'='*60}")
        
        # æµ‹è¯•æ‰§è¡Œ
        test_status = "âœ“ PASSED" if report['test_execution']['success'] else "âœ— FAILED"
        print(f"Test Execution: {test_status}")
        
        # è¦†ç›–ç‡
        coverage = report.get('coverage', {})
        coverage_percent = coverage.get('total_coverage', 0)
        print(f"Code Coverage: {coverage_percent:.1f}%")
        
        # è´¨é‡é—¨ç¦
        quality_gate = report.get('quality_gate', {})
        gate_status = "âœ“ PASSED" if quality_gate.get('overall_passed', False) else "âœ— FAILED"
        print(f"Quality Gate: {gate_status}")
        
        # å›å½’æµ‹è¯•
        regression = report.get('regression', {})
        regression_status = "âœ“ NO REGRESSION" if not regression.get('regression_detected', False) else "âœ— REGRESSION DETECTED"
        print(f"Regression: {regression_status}")
        
        print(f"\nReports saved to: {self.output_dir}")
        
        # æ€»ä½“çŠ¶æ€
        overall_success = (
            report['test_execution']['success'] and
            quality_gate.get('overall_passed', False) and
            not regression.get('regression_detected', False)
        )
        
        if overall_success:
            print("\nğŸ‰ All quality checks passed!")
        else:
            print("\nâš ï¸  Some quality checks failed!")
        
        return overall_success


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Run quality analysis for opitios_alpaca")
    parser.add_argument("--output-dir", default="quality_reports", help="Output directory")
    parser.add_argument("--coverage-only", action="store_true", help="Run coverage analysis only")
    parser.add_argument("--regression-only", action="store_true", help="Run regression tests only")
    
    args = parser.parse_args()
    
    manager = TestQualityManager(args.output_dir)
    
    if args.coverage_only:
        # åªè¿è¡Œè¦†ç›–ç‡åˆ†æ
        analyzer = CoverageAnalyzer()
        analyzer.start_coverage()
        # è¿™é‡Œéœ€è¦è¿è¡Œæµ‹è¯•...
        analyzer.stop_coverage()
        reports = analyzer.generate_coverage_report()
        print(f"Coverage reports generated: {reports}")
        
    elif args.regression_only:
        # åªè¿è¡Œå›å½’æµ‹è¯•
        suite = RegressionTestSuite()
        results = suite.run_regression_tests()
        comparison = suite.compare_with_baseline(results)
        print(f"Regression analysis: {comparison}")
        
    else:
        # è¿è¡Œå®Œæ•´è´¨é‡åˆ†æ
        report = manager.run_full_quality_analysis()
        success = manager.print_quality_summary(report)
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()